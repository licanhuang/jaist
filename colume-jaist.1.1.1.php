<h3>Journal of advances in information science and technology</h3>
</br>
<a href="jaist.1.1.php">Volume 1, Issue 1</a>, December 2023,  Pages: 1 - 6
</br>
</br>
<p style ="font-size:18px; color: blue;">Semantic Draw Engineering for Text-to-Image Creation </p>
</br>
<a href="1/1/jaist.1.1.1.pdf">Download article (PDF)</a>

</br>
</br>
<p style ="font-size:8px;"><strong>DOI</strong></p>
<p><a href="https://doi.org/10.5281/zenodo.10500576"> 10.5281/zenodo.10500576</a></p>
</br>

<p style ="font-size:8px;"><strong>Authors</strong></p>
<strong>Yang Li<sup>1</sup>, HuaQiang Jiang<sup>1,2</sup>, YangKai Wu<sup>3</sup> </strong>
</br>
1 school of information science and technology, hangzhou normal university , hangzhou, china
</br>
2 engineering research center of mobile health management systemï¼Œministry of education
</br>
3 Hangzhou Suosi Internet.

</br>
</br>
<p style ="font-size:8px;"><strong>Corresponding Author:</strong></p>
 


Huaqiang Jiang    (e-mail: jhq@hznu.edu.cn)  
</br>
</br>
<p style ="font-size:8px;">Received 16 August 2023, Accepted 8 December 2023, Available Online 18 December 2023.</p>
</br></br>

<p style ="font-size:8px;"><strong>Keywords</strong></p>


Prompt; Text-to-image;  Machine Learning ; Dell-e3; Midjourney ; Topic;  Composition.
</br>
</br>
<p style ="font-size:8px;"><strong>Abstract</strong></p>


Text-to-image generation is conducted through Generative Adversarial Networks (GANs) or transformer models. However, the current challenge lies in accurately generating images based on textual descriptions, especially in scenarios where the content and theme of the target image are ambiguous. In this paper, we propose a method that utilizes artificial intelligence models for thematic creativity, followed by a classification modeling of the actual painting process. The method involves converting all visual elements into quantifiable data structures before creating images. We evaluate the effectiveness of this approach in terms of semantic accuracy, image reproducibility, and computational efficiency, in comparison with existing image generation algorithms.
</br>
</br>

<p style ="font-size:8px;"><strong>Copyright</strong></p>


 @2023 The Authors. Published by Research Institute of Information Technology (Tokyo office), Hangzhou Domain Zones Technology Co., Ltd.
</br>
</br>

<p style ="font-size:8px;"><strong>Open Access</strong></p>

This is an open access article distributed under the CC BY-NC 4.0 
</br>
license CC BY-NC 4.0 : <a href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/ </a>.

